{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Odometer-Detection-Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTDs_Yi72fzP"
      },
      "source": [
        "#Odometer Detection - Stage 3\n",
        "\n",
        "**Team Members**\n",
        "\n",
        "Daysean Scott • Undergrad • (dscott52@uncc.edu) • 919-864-6832\n",
        "\n",
        "Galal Chamma • Undergrad • (gchamma@uncc.edu) • 919-675-9673\n",
        "\n",
        "Jaissruti Nanthakumar • Grad • (jnanthak@uncc.edu) • 336-405-4868\n",
        "\n",
        "Janani Sri Adanur Rammohan • Grad • (jadanurr@uncc.edu) • 980-345-9218 \n",
        "\n",
        "\n",
        "**GitLab:**\n",
        "https://cci-git.uncc.edu/itcs-4152-5152/fall-2021/project-8-odometer\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "# Modeling\n",
        " \n",
        "**Description of model**\n",
        "\n",
        "The model takes the following steps to achieve the reading of the mileage:\n",
        "\n",
        "1. Uses EasyOCR to find all text detections in the image\n",
        "\n",
        "2. Determines whether a ‘mi’ or ‘km’ text is found.\n",
        "\n",
        "3. Confirms that the text found is not ‘mph’ or ‘km/h’\n",
        "\n",
        "4. Checks the largest length detections and confirms if a number is attached to it, and returns it.\n",
        "\n",
        "5. If a number is not attached to the label text found, returns largest number found in image.\n",
        "\n",
        "\n",
        "We created our own Class in order to store important information about our detections, such as the **top-left** and **bottom-right** coordinates of the bounding box, as well as the **detected text**. \n",
        " \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "#Experimentation\n",
        "\n",
        "1. How did you set up your experiments?\n",
        "\n",
        "  By examining the provided Sonic Automotive images, we noticed a correlation between the position of the mileage number and its label, whether it was ‘mi’, ‘miles’, or ‘km’. That correlation allowed us to locate the mileage number after a series of steps that start with applying an optical character recognition algorithm over the image.\n",
        " \n",
        "2. Datasets used: Train, Validation, Test split information\n",
        "\n",
        "  Since our method, unlike a neural network, does not depend on training/testing split to work, we used approximately 20 images out of the provided 100 to come up with our solution. These 20 images had the mileage number in different locations compared to its label, and allowed us to come up with a solution that works with most of them.\n",
        " \n",
        "3. Experimentation with different models or methods\n",
        "\n",
        "  Besides this method, we are still experimenting with a neural network with training data composed of 2000+ images. So far, our current method has proved to work quite reliably with the images, but we will be checking whether a neural network would offer better results. \n",
        " \n",
        "4. Library and tools used\n",
        "\n",
        "  EasyOCR, OpenCV, Matplotlib\n",
        " \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#Literature Review\n",
        " \n",
        "**Motivation for using method (cite any existing work that you have used)**\n",
        " \n",
        "Effectiveness of Modern Text Recognition Solutions and Tools for Common Data Sources \n",
        "\n",
        "By: Kirill Smelyakov, Anastasiya Chupryna, Dmytro Darahan and Serhii Midina\n",
        "\n",
        "\n",
        "\n",
        "http://ceur-ws.org/Vol-2870/paper15.pdf\n",
        "\n",
        "* The motivation for using this method was sparked by the above mentioned paper, which describes the effectiveness and performance of two different OCR tools, EasyOCR and TesserOCR. The paper gave us the idea of detecting a key feature in the Odometer (the mileage label) using an OCR tool, and then determining the mileage based on that information.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#Results\n",
        "\n",
        "1. **Model Performance**\n",
        "\n",
        "  **Accuracy** = TP+TN / ALL | 98 + 0 / 113 = **87 %**\n",
        "\n",
        "  **Precision** = TP / TP+FP  | 98 / 98 + 12 = **89 %**\n",
        "\n",
        "  **Recall** = TP / TP+FN | 98 / 98 + 3 = **97 %**\n",
        " \n",
        "\n",
        "2. **Visual Results**\n",
        "\n",
        "  Using EasyOCR to determine the location of the bounding boxes and OpenCV to draw them, we were able to draw and label each detection as an overlay over the original image.\n",
        " \n",
        "  We used this technique to examine all detections in an image, determine the best way to manipulate these detections to find the mileage number, and then only display the mileage number bounding box.\n",
        " \n",
        "  Therefore, after running our algorithm, two output images are displayed. One containing all detections with their bounding boxes, in order to display everything that the OCR detected, and then a second image that only has the bounding box for the detection we used to extract the mileage number. Finally a print statement is displayed with the predicted mileage.\n",
        " \n",
        "3. **Graphs**\n",
        "\n",
        "  We do not have any graphs to show, since our method is not a neural network, therefore there are not any learning rate graphs, cost graphs, and so on. \n",
        " \n",
        " \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        " \n",
        "#Documentation\n",
        " \n",
        "**A well presented notebook describing the above tasks** \n",
        "\n",
        "Please see our code below\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTNuKUBw9cFj",
        "outputId": "2b8c7271-f98c-4326-8c9e-706e0601aa31"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__C4vmCW99o3",
        "outputId": "9bcc4a3d-c70b-4ccf-925a-452be4edce6d"
      },
      "source": [
        "working_dir = '/content/drive/My Drive/Sonics Auto'\n",
        "%cd '$working_dir'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Sonics Auto\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuMETly9FttR"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"labels.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEuV-n2NW9NH"
      },
      "source": [
        "true_mileage = []\n",
        "for actual in df['odometer']:\n",
        "  true_mileage.append(int(actual))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjgB9xbFGxxR",
        "outputId": "625a7f27-1c02-4839-b8a2-e31d128ba480"
      },
      "source": [
        "!pip install easyocr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting easyocr\n",
            "  Downloading easyocr-1.4.1-py3-none-any.whl (63.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 63.6 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from easyocr) (0.18.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from easyocr) (1.10.0+cu111)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from easyocr) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from easyocr) (1.19.5)\n",
            "Collecting python-bidi\n",
            "  Downloading python_bidi-0.4.2-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.7/dist-packages (from easyocr) (0.11.1+cu111)\n",
            "Requirement already satisfied: Pillow<8.3.0 in /usr/local/lib/python3.7/dist-packages (from easyocr) (7.1.2)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.5.4.60-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.6 MB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from easyocr) (3.13)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->easyocr) (3.10.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from python-bidi->easyocr) (1.15.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->easyocr) (2.4.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->easyocr) (3.2.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->easyocr) (2021.11.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->easyocr) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->easyocr) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->easyocr) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->easyocr) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->easyocr) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->easyocr) (2.8.2)\n",
            "Installing collected packages: python-bidi, opencv-python-headless, easyocr\n",
            "Successfully installed easyocr-1.4.1 opencv-python-headless-4.5.4.60 python-bidi-0.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eqlGQfZrU-O"
      },
      "source": [
        "import easyocr\n",
        "import torch\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "\n",
        "class Detection:\n",
        "  def __init__(self, label, top_left, bottom_right):\n",
        "    self.label = label\n",
        "    self.top_left = top_left\n",
        "    self.bottom_right = bottom_right\n",
        "\n",
        "def cleanAndFind(validDetections, containsLabel):\n",
        "\n",
        "  largestDetection = []\n",
        "  maxFound = 0\n",
        "  for det in validDetections:\n",
        "    # If string contains a label such as 'mi' or 'km'\n",
        "    if (containsLabel):\n",
        "      # find the index of 'mi' in the string\n",
        "      max_index = det.label.find('mi')  \n",
        "      # if 'mi' was not found in the string, look for 'km' instead\n",
        "      if (max_index == -1):\n",
        "        max_index = det.label.find('km')\n",
        "      # trimming the label from the number ('km...' or 'mi...')\n",
        "      mileage = det.label[0:max_index]\n",
        "    \n",
        "    # text does not contain a label\n",
        "    else:\n",
        "      mileage = det.label\n",
        "\n",
        "    # removing spaces in string\n",
        "    mileage = mileage.replace(\" \", \"\")\n",
        "\n",
        "    nonDigit_index = 0\n",
        "    for i, c in enumerate(mileage):\n",
        "      if not c.isdigit():\n",
        "          nonDigit_index = i\n",
        "          break\n",
        "    \n",
        "    if (nonDigit_index != 0):\n",
        "      mileage = mileage[0:nonDigit_index]\n",
        "\n",
        "    if (mileage.isdecimal()):\n",
        "      if (int(mileage) > maxFound):\n",
        "        maxFound = int(mileage)\n",
        "        largestDetection = [det,int(mileage)]\n",
        "\n",
        "  return largestDetection\n",
        "\n",
        "\n",
        "def displayImages(outputImages):\n",
        "  plt.figure(figsize=(20,20)) # specifying the overall grid size\n",
        "\n",
        "  for i in range(len(outputImages)):\n",
        "    plt.subplot(1,2,i+1)    # the number of expected images in the grid is (1 row, 2 columns = 2)\n",
        "    plt.imshow(outputImages[i])\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "def drawBox(IMAGE_PATH, detection, mileage, outputImages):\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    img = cv2.imread(IMAGE_PATH)\n",
        "    img = cv2.rectangle(img,detection.top_left,detection.bottom_right,(0,255,0),3)\n",
        "    img = cv2.putText(img,mileage,detection.top_left, font, 3,(255,255,255),7,cv2.LINE_AA)\n",
        "    outputImages.append(img)\n",
        "\n",
        "def find(image_path):\n",
        "\n",
        "  outputImages = []\n",
        "  IMAGE_PATH = image_path\n",
        "\n",
        "  reader = easyocr.Reader(['en'])\n",
        "  result = reader.readtext(IMAGE_PATH)\n",
        "  img = cv2.imread(IMAGE_PATH)\n",
        "  font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "\n",
        "\n",
        "  # Array to hold Detection objects, which have (Label, Top_Left, and Bottom_Right)\n",
        "  detections = []\n",
        "\n",
        "  for i in range (len(result)):\n",
        "    # Fetching the data we care about from the result\n",
        "    top_left = (int(result[i][0][0][0]),int(result[i][0][0][1]))\n",
        "    bottom_right = (int(result[i][0][2][0]),int(result[i][0][2][1]))\n",
        "    text = str(result[i][1])\n",
        "\n",
        "    # creating an object for the label and information and adding them to array, i == ID\n",
        "    det = Detection(text, top_left, bottom_right)\n",
        "    detections.append(det)\n",
        "\n",
        "    # Drawing the boxes and lables on the image\n",
        "    img = cv2.rectangle(img,top_left,bottom_right,(0,255,0),3)\n",
        "    img = cv2.putText(img,text,top_left, font, 2,(255,255,255),7,cv2.LINE_AA)\n",
        "\n",
        "  \n",
        "  outputImages.append(img)\n",
        "\n",
        "\n",
        "  possibleDetections = []\n",
        "  for det in detections:\n",
        "    label = det.label\n",
        "    # changed mi to m\n",
        "    if ('mi' in label.lower() or 'km' in label.lower()):\n",
        "      if (not ('km/' in label.lower() or 'mi/' in label.lower())):\n",
        "        possibleDetections.append(det)\n",
        "\n",
        "  # did we detect any 'mi' or 'km' ???\n",
        "  if (len(possibleDetections)) > 0:\n",
        "\n",
        "    # find the highest number WITH a label\n",
        "    validDetection = cleanAndFind(possibleDetections, True)\n",
        "    if (len(validDetection)) > 0:\n",
        "      mileage = str(validDetection[1])\n",
        "      drawBox(IMAGE_PATH, validDetection[0], mileage, outputImages)\n",
        "      displayImages(outputImages)\n",
        "      print(\"mileage detected:\", mileage); return mileage\n",
        "    \n",
        "    # Cleaned array returned no mileage, but a label 'mi' or 'km' was actually found. return maximum number detected \n",
        "    else:\n",
        "      #print(\"---- STEP 2 ACTIVATED ----\")\n",
        "      # using False for boolean since we don't care about slicing 'mi' or 'km' from strings\n",
        "      validDetection = cleanAndFind(detections, False)\n",
        "      if (len(validDetection)) > 0:\n",
        "        mileage = str(validDetection[1])\n",
        "        drawBox(IMAGE_PATH, validDetection[0], mileage, outputImages)\n",
        "        displayImages(outputImages)\n",
        "        print(\"mileage detected:\", mileage); return mileage\n",
        "      else:\n",
        "        displayImages(outputImages)\n",
        "        print(\"Mileage could not be detected \"); return \"NotFound\"\n",
        "\n",
        "\n",
        "  # no label was found in the image, return maximum number detected  \n",
        "  else:\n",
        "      # using False for boolean since we don't care about slicing 'mi' or 'km' from strings\n",
        "      validDetection = cleanAndFind(detections, False)\n",
        "      if (len(validDetection)) > 0:\n",
        "        mileage = str(validDetection[1])\n",
        "        drawBox(IMAGE_PATH, validDetection[0], mileage, outputImages)\n",
        "        displayImages(outputImages)\n",
        "        print(\"mileage detected:\", mileage); return mileage\n",
        "      else:\n",
        "        displayImages(outputImages)\n",
        "        print(\"Mileage could not be detected \"); return \"NotFound\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9ONX0XKQWEqc",
        "outputId": "45222706-06f4-45da-e548-00b08c2ea191"
      },
      "source": [
        "predictions = []\n",
        "\n",
        "counter = 1\n",
        "for i, image in enumerate(df['filename']):\n",
        "  print(\"\\n\\n\")\n",
        "  print(\"Currently examining image [\"+ str(counter) + '/' + str(len(df))+\"]\")\n",
        "  p = find('images/'+image)\n",
        "  predictions.append(p)\n",
        "  counter = counter+1\n",
        "  if (p.isdecimal()):\n",
        "    if (int(true_mileage[i]) == int(p)):\n",
        "      print(\"Correct!\")\n",
        "    else:\n",
        "      print(\"Incorrect :(\")\n",
        "  else:\n",
        "    print(\"Incorrect :(\")\n",
        "\n",
        "\n",
        "for i in range(len(true_mileage)):\n",
        "  print(i, \") \", \"Actual: \", true_mileage[i], \"      Prediction: \", predictions[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "annrOGeFbG30",
        "outputId": "9314c5a3-c9ca-400c-e2cc-5bb2aa14b426"
      },
      "source": [
        "tp = 0\n",
        "fp = 0\n",
        "fn = 0\n",
        "trueFalse = []\n",
        "for i in range(len(true_mileage)):\n",
        "  if (str(predictions[i]) == \"NotFound\"):\n",
        "    fn = fn + 1\n",
        "    trueFalse.append(\"FALSE\")\n",
        "  if (str(true_mileage[i]) == str(predictions[i])):\n",
        "    tp = tp + 1\n",
        "    trueFalse.append(\"TRUE\")\n",
        "  elif (str(true_mileage[i]) != str(predictions[i]) and (str(predictions[i]) != \"NotFound\")):\n",
        "    fp = fp + 1\n",
        "    trueFalse.append(\"FALSE\") \n",
        "\n",
        "print(\"All Data: \", len(true_mileage), 'images')\n",
        "print(\"TP:\", tp)\n",
        "print(\"TN: 0\")\n",
        "print(\"FP:\", fp)\n",
        "print(\"FN:\", fn)\n",
        "print(\"-----------------\")\n",
        "print(\"Accuracy = TP+TN / ALL |\", tp, \"+ 0 /\",len(true_mileage), \"|\", (tp/len(true_mileage)))\n",
        "print(\"Recall = TP / TP+FN |\", tp, \"/\",tp, \"+\", fn, \"|\", tp/(tp+fn))\n",
        "print(\"Precision = TP / TP+FP  |\", tp, \"/\",tp, \"+\", fp, \"|\", tp/(tp+fp))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Data:  113 images\n",
            "TP: 98\n",
            "TN: 0\n",
            "FP: 12\n",
            "FN: 3\n",
            "-----------------\n",
            "Accuracy = TP+TN / ALL | 98 + 0 / 113 | 0.8672566371681416\n",
            "Recall = TP / TP+FN | 98 / 98 + 3 | 0.9702970297029703\n",
            "Precision = TP / TP+FP  | 98 / 98 + 12 | 0.8909090909090909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEKnxHVq_-e9"
      },
      "source": [
        "# Saving the data to a csv file\n",
        "df['Prediction'] = predictions\n",
        "df['Validity'] = trueFalse\n",
        "df1 = df.drop(columns=['xmin', 'xmax', 'ymin', 'ymax'])\n",
        "df1.to_csv(\"prediction.csv\", sep=\",\", encoding='utf-8', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}